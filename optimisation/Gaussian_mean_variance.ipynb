{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process Mean-variance trading with signatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "O1hdKLAhssTm",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myfinance\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01myf\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmogptk\u001b[39;00m  \u001b[38;5;66;03m# pytorch >= 11.0 is required\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;66;03m# pytorch 11.0 is used\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'"
     ]
    }
   ],
   "source": [
    "from functools import partial, reduce\n",
    "from collections import OrderedDict\n",
    "\n",
    "import scipy \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import mogptk  # pytorch >= 11.0 is required\n",
    "import torch # pytorch 11.0 is used\n",
    "import signatory # if cannot find a version compatible with pytorch, \n",
    "                 # install locally follows insturcction on https://github.com/patrick-kidger/signatory\n",
    "\n",
    "from src.signature_trading import SignatureTrading,trading_strategies,GaussianProcessExpectedSiganture,_transformation\n",
    "from src.free_lie_algebra import *\n",
    "from src.transformations import LeadLag, HoffLeadLag, AddTime, ScalePaths, TranslatePaths\n",
    "from src.optimisation.signature import *\n",
    "from src.helper_functions.signature_helper_functions import get_signature_weights, \\\n",
    "    get_signature_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get data\n",
    "_N = 4\n",
    "\n",
    "df      = pd.read_csv('stocks.csv', index_col=0)\n",
    "names   = df.columns[:_N].to_list()\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "names            = df.columns[:_N].to_list()\n",
    "indexes          = df.index.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic setup for signature trading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_result_df =pd.DataFrame(columns= ['Capital','PnL','weight GE','weight IBM','weight JPM','weight KO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[names].loc[(df.index > pd.Timestamp('2017-01-01')) & (df.index < pd.Timestamp('2022-01-01'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may first look at the traditional Markowitz mean-variance optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df2)-28+1):\n",
    "    if len(df2)-5*i <28:\n",
    "        break\n",
    "    df3 = df2[5*i:28+5*i]\n",
    "    prices = df3.to_numpy()\n",
    "    df3['time'] = np.linspace(0,1,len(df3))\n",
    "    df_train = df3[:23]\n",
    "    r = (prices[:-1]-prices[1:])/prices[1:]\n",
    "    train_r = r[:22]\n",
    "    test_r = r[22:]\n",
    "    df_test = df3[names+['time']][22:]\n",
    "    if i==0:\n",
    "        start_date = df_test.index[0]\n",
    "    start_capital = capital_mv[-1]\n",
    "    expt_mean,expt_cov = np.mean(train_r,axis=0),np.cov(train_r.T)\n",
    "    mv_weights = np.array([\n",
    "            mean_variance_optim(expt_mean,expt_cov, pnl) for pnl in np.linspace(0,0.1,50)\n",
    "         ])\n",
    "    risks = [np.matmul(w.T, np.matmul(expt_cov, w)) for w in mv_weights]\n",
    "    pnls = [np.matmul(w.T, expt_mean) for w in mv_weights]\n",
    "    weight_mv = mv_weights[np.argmin(risks)]\n",
    "    for j in range(len(test_r)):\n",
    "        mv_result = []\n",
    "        practical_pnl = np.matmul(weight_mv.T, test_r[j])\n",
    "\n",
    "        capital_mv.append(capital_mv[-1]*(1+practical_pnl))\n",
    "        mv_result.append(capital_mv[-1])\n",
    "        mv_result.append(practical_pnl)\n",
    "        mv_result += list(weight_mv)\n",
    "        mv_result_df.loc[df_test.index[j+1]] = mv_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtest:\n",
    "\n",
    "We backtest the performance with stock 'GE','IBM','JPM' and 'KO' from 2017-01-01 to 2022-01-01. We also compute weights of each asset of Markowitz mean-variance portofolio with empirical mean and variance of assets and mean variance estimated from the fitted Gaussain Process model.The PnL and value of portofolios are recoreded as well as benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_mv = [100000]\n",
    "\n",
    "for i in range(len(df2)-28+1):\n",
    "    if len(df2)-5*i <28:\n",
    "        break\n",
    "    df3 = df2[5*i:28+5*i]\n",
    "    prices = df3.to_numpy()\n",
    "    df3['time'] = np.linspace(0,1,len(df3))\n",
    "    df_train = df3[:23]\n",
    "    r = (prices[:-1]-prices[1:])/prices[1:]\n",
    "    train_r = r[:22]\n",
    "    test_r = r[22:]\n",
    "    df_test = df3[names+['time']][22:]\n",
    "    if i==0:\n",
    "        start_date = df_test.index[0]\n",
    "    start_capital = capital_mv[-1]\n",
    "    expt_mean,expt_cov = np.mean(train_r,axis=0),np.cov(train_r.T)\n",
    "    mv_weights = np.array([\n",
    "            mean_variance_optim(expt_mean,expt_cov, pnl) for pnl in np.linspace(0,0.1,50)\n",
    "         ])\n",
    "    risks = [np.matmul(w.T, np.matmul(expt_cov, w)) for w in mv_weights]\n",
    "    pnls = [np.matmul(w.T, expt_mean) for w in mv_weights]\n",
    "    weight_mv = mv_weights[np.argmin(risks)]\n",
    "    for j in range(len(test_r)):\n",
    "        mv_result = []\n",
    "        practical_pnl = np.matmul(weight_mv.T, test_r[j])\n",
    "\n",
    "        capital_mv.append(capital_mv[-1]*(1+practical_pnl))\n",
    "        mv_result.append(capital_mv[-1])\n",
    "        mv_result.append(practical_pnl)\n",
    "        mv_result += list(weight_mv)\n",
    "        mv_result_df.loc[df_test.index[j+1]] = mv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_lmc(data,Q=3,init_method = 'BNSE',method = 'Adam',lr = 0.01,iters = 500,training_size=23,training_in_gpu=0):\n",
    "        \"\"\"\n",
    "        Return a trained lmc model for given data\n",
    "        \n",
    "        Arugments:\n",
    "        ---------------\n",
    "        backtest=False: bool\n",
    "            mode that is backtest friendly\n",
    "        training_size: float/int\n",
    "            set the size of training set\n",
    "        For the other arguments, we refer [1] for a detailed explanation\n",
    "\n",
    "        Reference:\n",
    "        --------------\n",
    "        [1]  T. de Wolff, A. Cuevas, and F. Tobar. MOGPTK: The Multi-Output Gaussian Process Toolkit. Neurocomputing, 2020\n",
    "        \"\"\"\n",
    "        # Default training size is 23 if not specified\n",
    "        if training_in_gpu!=None and torch.cuda.is_available():\n",
    "            mogptk.use_gpu(training_in_gpu)\n",
    "        elif not torch.cuda.is_available():\n",
    "            print(\"CUDA is not available.\")\n",
    "        else:\n",
    "            mogptk.use_cpu()\n",
    "        lmc_dataset = mogptk.LoadDataFrame(data, x_col='time', y_col=names)\n",
    "        for channel in lmc_dataset:\n",
    "            channel.transform(mogptk.TransformNormalize())\n",
    "            channel.transform(mogptk.TransformDetrend())\n",
    "        for name in names:\n",
    "            # remove the data after `training_size` as test data \n",
    "            lmc_dataset[name].remove_range(data.time[training_size],None)\n",
    "\n",
    "        lmc = mogptk.SM_LMC(lmc_dataset, Q=Q,inference=mogptk.Exact())\n",
    "        lmc.init_parameters(init_method)\n",
    "        lmc.train(method=method, lr=lr, iters=iters, verbose=False, error='MSE')\n",
    "        return lmc\n",
    "\n",
    "#dt = timedelta_to_fraction_of_year(np.diff(indexes).mean())\n",
    "# set the transofrmation\n",
    "transformations = _transformation(_N,dt=None,_transformations=OrderedDict(\n",
    "                {\"AddTime\": False, \"TranslatePaths\": False, \"ScalePaths\": False, \"LeadLag\": False, \"HoffLeadLag\":True}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_result_df = pd.DataFrame(columns= ['Capital','PnL','weight GE','weight IBM','weight JPM','weight KO'])\n",
    "gmv_result_df = pd.DataFrame(columns= ['Capital','PnL','weight GE','weight IBM','weight JPM','weight KO'])\n",
    "initial_capital = 100000\n",
    "capital_sig = [initial_capital]\n",
    "capital_gmv = [initial_capital]\n",
    "for i in range(len(df2)-28+1):\n",
    "    if len(df2)-5*i <28:\n",
    "        break\n",
    "    df3 = df2[5*i:28+5*i]\n",
    "    df_train = df3[:23]\n",
    "    \n",
    "    gpm = training_lmc(df3)\n",
    "    ges = GaussianProcessExpectedSiganture(gpm)\n",
    "    ges._get_paths()\n",
    "    sig_trading = SignatureTrading(df3,ges,level=2)\n",
    "    sig_trading._get_funcs(transformation=transformations)\n",
    "    test_time = df_test.time.to_numpy()\n",
    "\n",
    "    price = df_test.iloc[:,:_N].to_numpy()\n",
    "\n",
    "    for j in range(len(test_time)-1):\n",
    "        result = []\n",
    "        gmv_result = []\n",
    "\n",
    "        es_weights = sig_trading.get_weights(price[j])\n",
    "        weight = es_weights/np.sum(es_weights)\n",
    "\n",
    "        shares = capital_sig[-1]*weight/price[j]\n",
    "                \n",
    "        capital_sig.append(np.sum(shares * price[j+1]))\n",
    "\n",
    "        result.append(capital_sig[-1])\n",
    "        result.append((capital_sig[-1]-capital_sig[-2])/capital_sig[-2])\n",
    "        result += list(weight)\n",
    "        \n",
    "        expt_mean,expt_cov = gpm.gpr.predict(torch.tensor([[i,test_time[j]] for i in range(4)]),full=True)\n",
    "        gmv_weights = np.array([\n",
    "            mean_variance_optim(expt_mean,expt_cov, pnl) for pnl in np.linspace(0,0.1,50)\n",
    "         ])\n",
    "\n",
    "        pnls = [np.matmul(w.T, expt_mean) for w in gmv_weights]\n",
    "\n",
    "        risks = [np.matmul(w.T, np.matmul(expt_cov, w)) for w in gmv_weights]\n",
    "        weight_gmv = gmv_weights[np.argmin(risks)]\n",
    "        shares_gmv = capital_gmv[-1]*weight_gmv/price[j]\n",
    "        capital_gmv.append(np.sum(shares_gmv * price[j+1]))\n",
    "        gmv_result.append(capital_gmv[-1])\n",
    "        gmv_result.append((capital_gmv[-1]-capital_gmv[-2])/capital_gmv[-2])\n",
    "        gmv_result += list(weight_gmv)\n",
    "\n",
    "        sig_result_df.loc[df_test.index[j+1]] = result\n",
    "        gmv_result_df.loc[df_test.index[j+1]] = gmv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_result_df.to_csv(\"mv_result.csv\")\n",
    "sig_result_df.to_csv(\"sig_result.csv\")\n",
    "gmv_result_df.to_csv(\"gmv_result.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the daily PnL of signature trading. We may see a big drop at the beginning of 2021. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Daily PnL with signature trading strategy\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Daily PnL\")\n",
    "plt.plot(gmv_result_df.PnL,label='gaussian mean-variance')\n",
    "plt.plot(mv_result_df.PnL,label='mean-variance')\n",
    "plt.plot(sig_result_df.PnL,label='signature trading')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the drop and see what happens,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1[names].loc[(df1.index > pd.Timestamp('2020-02-08')) & (df1.index < pd.Timestamp('2020-03-20'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2[0:28]\n",
    "df_train = df3[:23]\n",
    "df_test = df3[names][22:]\n",
    "\n",
    "ges = GaussianProcessExpectedSiganture(training_lmc(df3))\n",
    "ges._get_paths()\n",
    "sig_trading = SignatureTrading(df3,ges,level=2)\n",
    "sig_trading._get_coeffs(transformation=transformations)\n",
    "expected_signatures_ = np.array([get_signature_values(sig_trading.normed_price[np.newaxis, :i, :], 2) \\\n",
    "                                 for i in range(22,len(df3)-1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may see that the logarithm of the absolute value of the 'optimal' variance of the portofolio is negative with a large magnitude. It is clear that the optimization algorithm fails on the time period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,sig_var = sig_trading._get_coeffs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"log(-var) of the optimal variance trained in the period 2020-02-10 to 2020-03-19\")\n",
    "plt.plot(np.log(-sig_var))\n",
    "plt.ylabel(\"log(-var)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the four assets are predicted to show a decreasing trend. This 'wrong' way correlation and an inaccurate approximation of signatures cause this failure of convergence of the optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_trading.es.lmc.plot_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[names].loc[(df.index > pd.Timestamp('2021-11-18')) & (df.index <= pd.Timestamp('2021-12-30'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply the ReLU function on the weights and then normalized them to get a new set of weights that are between 0 and 1. Below is the plot of how this would affect the strategy, and we can see that extreme values are obviously reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noshorting_sig_result_df = pd.DataFrame(columns= ['Capital','PnL','weight GE','weight IBM','weight JPM','weight KO'])\n",
    "capital_nssig = [100000]\n",
    "for i in range(len(df2)-28+1):\n",
    "    if len(df2)-5*i <28:\n",
    "        break\n",
    "    df3 = df2[5*i:28+5*i]\n",
    "\n",
    "    df3['time'] = np.linspace(0,1,len(df3))\n",
    "    df_train = df3[:23]\n",
    "    df_test = df3[names+['time']][22:]\n",
    "    price = df_test.iloc[:,:_N].to_numpy()\n",
    "    for j in range(len(df_test)-1):\n",
    "        result = []\n",
    "        if df_test.index[j] in sig_result_df.index:\n",
    "            es_weights = sig_result_df.loc[df_test.index[j],\\\n",
    "                                        ['weight GE','weight IBM','weight JPM','weight KO']].to_numpy()\n",
    "            pos_weight = es_weights*np.array(es_weights>0,dtype=np.float64)\n",
    "            weight = pos_weight/np.sum(pos_weight)\n",
    "\n",
    "            shares = capital_nssig[-1]*weight/price[j]\n",
    "\n",
    "            capital_nssig.append(np.sum(shares * price[j+1]))\n",
    "\n",
    "            result.append(capital_nssig[-1])\n",
    "            result.append((capital_nssig[-1]-capital_nssig[-2])/capital_nssig[-2])\n",
    "\n",
    "            result += list(weight)\n",
    "            noshorting_sig_result_df.loc[df_test.index[j+1]] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Daily PnL with signature trading strategy vs no shorting\")\n",
    "#plt.plot(result_df[result_df8.PnL>-0.2].PnL,label='signature trading')\n",
    "plt.plot(sig_result_df.PnL,label='signature trading')\n",
    "plt.plot(noshorting_sig_result_df.PnL,label='siganture trading without shorting',alpha=0.5)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Daily PnL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compare the signature trading strategy without shorting to (Gaussain) Markowitz mean-variance portofolio, and we can see that the PnL indeed becomes more stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mv_result_df.PnL,label='usual markowitz')\n",
    "plt.plot(gmv_result_df.PnL,label='gaussian process markowitz')\n",
    "#plt.plot(result_df3[result_df3.PnL>-0.2].PnL)\n",
    "plt.plot(noshorting_sig_result_df.PnL,label='signature')\n",
    "plt.title(\"Daily PnL with different trading strategies\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Daily PnL\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noshorting_sig_result_df.to_csv(\"no shorting.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the plot of change of portofolio values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Dality Portfolio values for three different strategies\")\n",
    "plt.plot(noshorting_sig_result_df.Capital,label='signature trading without shorting')\n",
    "plt.plot(sig_result_df.Capital,label='signature trading')\n",
    "plt.plot(gmv_result_df.Capital,label='gaussian process markowitz')\n",
    "plt.plot(mv_result_df.Capital,label='usual markowitz')\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Capital\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
